{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279aa260",
   "metadata": {},
   "source": [
    "# **Data Augmentation with (Conditional) Gan** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5c0a9",
   "metadata": {},
   "source": [
    "**The objective is to verify if a dataset of synthetic images generated from a GAN can be used to effectively train a classifier, and how it compares to training the classifier with the original training set.**\n",
    "**Verify if synthetic images can serve as additional data in addition to the original training set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0119bb8",
   "metadata": {},
   "source": [
    "Dataset - **CIFAR10**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33cb8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (50000, 32, 32, 3)\n",
      "Shape of training labels: (50000, 1)\n",
      " No GPU found. TensorFlow will use the CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Loading the CIFAR-10 dataset \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# --- Preprocessing ---\n",
    "# Normalize pixel values from the [0, 255] range to the [-1, 1] range.\n",
    "# This is a common practice for GANs as it helps the generator's\n",
    "# output (using a tanh activation) match the real image distribution.\n",
    "x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "# Print the shape of the training data to confirm\n",
    "print(\"Shape of training images:\", x_train.shape)\n",
    "print(\"Shape of training labels:\", y_train.shape)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  # If GPUs are found, TensorFlow will automatically use them\n",
    "  print(f\" GPU(s) found: {len(gpus)}\")\n",
    "  for gpu in gpus:\n",
    "    print(f\"  - {gpu}\")\n",
    "else:\n",
    "  # If no GPUs are found, TensorFlow will use the CPU\n",
    "  print(\" No GPU found. TensorFlow will use the CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31489e",
   "metadata": {},
   "source": [
    "#### Building the Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b2bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate, Embedding\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# --- Define Constants ---\n",
    "IMG_SHAPE = (32, 32, 3)\n",
    "NUM_CLASSES = 10\n",
    "LATENT_DIM = 128 # Increased latent dim for potentially better quality\n",
    "\n",
    "def build_critic():\n",
    "    # Input for the image\n",
    "    img_input = Input(shape=IMG_SHAPE)\n",
    "\n",
    "    # Input for the class label\n",
    "    label_input = Input(shape=(1,))\n",
    "    \n",
    "    # Convert label into a dense vector and reshape\n",
    "    label_embedding = Embedding(NUM_CLASSES, 50)(label_input)\n",
    "    label_embedding = Dense(IMG_SHAPE[0] * IMG_SHAPE[1])(label_embedding)\n",
    "    label_embedding = Reshape((IMG_SHAPE[0], IMG_SHAPE[1], 1))(label_embedding)\n",
    "\n",
    "    # Combine the label embedding and the image\n",
    "    concatenated_input = Concatenate()([img_input, label_embedding])\n",
    "\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(concatenated_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # --- KEY CHANGE ---\n",
    "    # No sigmoid activation. The critic outputs a raw score (a scalar).\n",
    "    x = Dense(1)(x)\n",
    "\n",
    "    # Create the critic model\n",
    "    critic = Model([img_input, label_input], x, name=\"critic\")\n",
    "    return critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be5b52",
   "metadata": {},
   "source": [
    "#### Building the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cfec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    # Input for the random noise\n",
    "    noise_input = Input(shape=(LATENT_DIM,))\n",
    "\n",
    "    # Input for the class label\n",
    "    label_input = Input(shape=(1,))\n",
    "    \n",
    "    # Process the label\n",
    "    label_embedding = Embedding(NUM_CLASSES, 50)(label_input)\n",
    "    label_embedding = Dense(4 * 4)(label_embedding)\n",
    "    label_embedding = Reshape((4, 4, 1))(label_embedding)\n",
    "\n",
    "    # Process the noise\n",
    "    noise = Dense(256 * 4 * 4, activation='relu')(noise_input)\n",
    "    noise = Reshape((4, 4, 256))(noise)\n",
    "\n",
    "    # Combine the processed noise and label\n",
    "    concatenated_input = Concatenate()([noise, label_embedding])\n",
    "\n",
    "    # Upsample to a full-sized image\n",
    "    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(concatenated_input)\n",
    "    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "\n",
    "    # Create the generator model\n",
    "    generator = Model([noise_input, label_input], x, name=\"generator\")\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccb45a",
   "metadata": {},
   "source": [
    "#### Building and Compiling the cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5222d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(tf.keras.Model):\n",
    "    def __init__(self, critic, generator, latent_dim, critic_extra_steps=5, gp_weight=10.0):\n",
    "        super().__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.c_extra_steps = critic_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, c_optimizer, g_optimizer):\n",
    "        super().compile()\n",
    "        self.c_optimizer = c_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        # We don't use the standard Keras loss, so we define our own metrics\n",
    "        self.c_loss_metric = tf.keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.c_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images, labels):\n",
    "        \"\"\" Calculates the gradient penalty. \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the critic output for this interpolated image.\n",
    "            pred = self.critic([interpolated, labels], training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # --- Train the Critic ---\n",
    "        # WGAN-GP trains the critic multiple times for each generator train step\n",
    "        for i in range(self.c_extra_steps):\n",
    "            # Get random noise\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator([random_latent_vectors, labels], training=True)\n",
    "                # Get the critic scores for real images\n",
    "                real_output = self.critic([real_images, labels], training=True)\n",
    "                # Get the critic scores for fake images\n",
    "                fake_output = self.critic([fake_images, labels], training=True)\n",
    "\n",
    "                # Calculate the Wasserstein loss\n",
    "                c_cost = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images, labels)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                c_loss = c_cost + gp * self.gp_weight\n",
    "\n",
    "            # Calculate and apply gradients\n",
    "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(c_gradient, self.critic.trainable_variables))\n",
    "\n",
    "        # --- Train the Generator ---\n",
    "        # Get random noise\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images\n",
    "            generated_images = self.generator([random_latent_vectors, labels], training=True)\n",
    "            # Get the critic scores for the fake images\n",
    "            gen_img_output = self.critic([generated_images, labels], training=True)\n",
    "            # Calculate the generator loss (we want to maximize the critic's score for fake images)\n",
    "            g_loss = -tf.reduce_mean(gen_img_output)\n",
    "\n",
    "        # Calculate and apply gradients\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.c_loss_metric.update_state(c_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {\"c_loss\": self.c_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ca99c",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a callback to periodically save generated images\n",
    "class ImageSampler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=10, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 == 0: # Sample every 5 epochs\n",
    "            noise = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "            labels = tf.constant(np.arange(0, self.num_img).reshape(-1, 1))\n",
    "            \n",
    "            generated_images = self.model.generator.predict([noise, labels])\n",
    "            \n",
    "            # Rescale images from [-1, 1] to [0, 1] for plotting\n",
    "            generated_images = (generated_images + 1) / 2.0\n",
    "            \n",
    "            fig, axs = plt.subplots(1, self.num_img, figsize=(15, 3))\n",
    "            for i in range(self.num_img):\n",
    "                axs[i].imshow(generated_images[i])\n",
    "                axs[i].set_title(f\"Class: {labels[i].numpy()[0]}\")\n",
    "                axs[i].axis('off')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "EPOCHS = 1000 # WGAN-GP often converges faster.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# --- Build and Compile the WGAN-GP ---\n",
    "critic = build_critic()\n",
    "generator = build_generator()\n",
    "\n",
    "wgan = WGAN(critic=critic, generator=generator, latent_dim=LATENT_DIM)\n",
    "\n",
    "wgan.compile(\n",
    "    c_optimizer=Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    "    g_optimizer=Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9),\n",
    ")\n",
    "\n",
    "# --- Start Training ---\n",
    "# Create an instance of our image sampler callback\n",
    "sampler_callback = ImageSampler(latent_dim=LATENT_DIM)\n",
    "\n",
    "# Use tf.data to prepare the dataset for efficient training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE)\n",
    "\n",
    "# The .fit() method will now handle the entire training loop for you!\n",
    "wgan.fit(train_dataset, epochs=EPOCHS, callbacks=[sampler_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
